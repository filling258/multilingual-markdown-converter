{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71cb104c-588c-4a0d-b888-6c8449a2bc01",
   "metadata": {},
   "source": [
    "# Tokenizing and Translating Markdown with OpenAI\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we will implement a pipeline to tokenize a markdown document, split it into chunks at multiple newlines, translate those chunks using OpenAI's LLMs, and reconstruct the full document while retaining original formatting.\n",
    "\n",
    "Specifically, we will:\n",
    "\n",
    "- Read in a markdown file \n",
    "- Tokenize the text into words, punctuation, etc.\n",
    "- Count the number of tokens\n",
    "- Split the tokens into chunks whenever there are multiple successive newlines \n",
    "- Translate each chunk into another language using OpenAI's translation LLMs\n",
    "- R